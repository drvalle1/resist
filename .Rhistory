#- generate phi1 and phi2 in such a way that things are not clearly separable
#- generate theta in such a way that we don't have approx. pure time segments
nbehavior=5
ncat.data=c(6,10,2,8,5)
ndata.types=length(ncat.data)
nobs.tsegm=100 #number of observations per time segment
#get parameters
phi=list()
for (i in 1:ndata.types){
phi[[i]]=rdirichlet(nbehavior,alpha=rep(0.1,ncat.data[i]))
}
theta.true=theta=rdirichlet(ntsegm,alpha=rep(0.1,nbehavior))
phi.true=phi
#look at these parameters
boxplot(theta)
apply(theta>0.95,2,mean)
par(mfrow=c(ceiling(nbehavior/2),2),mar=rep(1,4))
for (i in 1:nbehavior) plot(phi.true[[1]][i,],type='h',main=i)
for (i in 1:nbehavior) plot(phi.true[[2]][i,],type='h',main=i)
#create storage space
y.disagg.true=z.true=list()
for (i in 1:ndata.types){
z.true[[i]]=matrix(0,ntsegm,nbehavior)
y.disagg.true[[i]]=array(NA,dim=c(ntsegm,ncat.data[i],nbehavior))
}
#generate disaggregated data (already partitioned into different behaviors)
for (j in 1:ndata.types){
for (t in 1:ntsegm){
z=rmultinom(1,size=nobs.tsegm,prob=theta[t,]) #number of obs from each behavior
z.true[[j]][t,]=z
for (k in 1:nbehavior){
y.disagg.true[[j]][t,,k]=rmultinom(1,size=z[k],prob=phi[[j]][k,]) #number of obs in each categ from each behavior
}
}
}
#aggregate data
y=numeric()
for (j in 1:ndata.types){
aux=apply(y.disagg.true[[j]],1:2,sum) #sum across behaviors
nomes=paste0('y',j,'.',1:ncat.data[j])
colnames(aux)=nomes
y=cbind(y,aux)
}
plot(res$loglikel[100:ngibbs],type='l')
compare=function(true1,estim1){
rango=range(c(true1,estim1))
plot(true1,estim1,ylim=rango,xlim=rango)
lines(rango,rango,col='red')
}
theta.estim=matrix(res$theta[ngibbs,],nrow(dat),nmaxclust)
boxplot(theta.estim)
boxplot(theta.estim)
nclust=5
z1.tmp=apply(res$z.agg[[1]],c(1,3),sum)[,1:nclust]
ordem=numeric()
for (i in 1:ncol(z.true[[1]])){
tmp=rep(NA,ncol(z.true[[1]]))
for (j in 1:ncol(z1.tmp)){
tmp[j]=cor(cbind(z1.tmp[,j],z.true[[1]][,i]))[1,2]
}
ind=which(tmp==max(tmp))
ordem=c(ordem,ind)
}
par(mfrow=c(ceiling(ndata.types/2),2),mar=rep(1,4))
for (j in 1:ndata.types){
z1.tmp=apply(res$z.agg[[j]],c(1,3),sum)[,1:nclust]
compare(z.true[[j]],z1.tmp[,ordem])
}
j
par(mfrow=c(ceiling(ndata.types/2),2),mar=rep(1,4))
z1.tmp=apply(res$z.agg[[j]],c(1,3),sum)[,1:nclust]
length(res$z.agg)
rm(list=ls(all=TRUE))
library('MCMCpack')
library('Rcpp')
set.seed(2)
setwd('U:\\GIT_models\\git_LDA_behavior')
source('LDA_behavior_function.R')
source('LDA_behavior_gibbs.R')
sourceCpp('aux1.cpp')
dat=read.csv('fake data.csv',as.is=T)
head(dat)
rm(list=ls(all=TRUE))
library('MCMCpack')
library('Rcpp')
set.seed(2)
setwd('U:\\GIT_models\\git_LDA_behavior')
source('LDA_behavior_function.R')
source('LDA_behavior_gibbs.R')
sourceCpp('aux1.cpp')
dat=read.csv('fake data.csv',as.is=T)
#prior
gamma1=0.1
alpha=0.1
#prepare for gibbs
ngibbs=1000
nburn=ngibbs/2
nmaxclust=10
ndata.types=5
res=LDA_behavior_gibbs(dat=dat,gamma1=gamma1,alpha=alpha,
ngibbs=ngibbs,nmaxclust=nmaxclust,
nburn=nburn,ndata.types=ndata.types)
library('MCMCpack')
set.seed(2)
#basic settings
ntsegm=20*40 #overall number of time segments
#be careful with large nbehavior because it is easy to:
#- generate phi1 and phi2 in such a way that things are not clearly separable
#- generate theta in such a way that we don't have approx. pure time segments
nbehavior=5
ncat.data=c(6,10,2,8,5)
ndata.types=length(ncat.data)
nobs.tsegm=100 #number of observations per time segment
#get parameters
phi=list()
for (i in 1:ndata.types){
phi[[i]]=rdirichlet(nbehavior,alpha=rep(0.1,ncat.data[i]))
}
theta.true=theta=rdirichlet(ntsegm,alpha=rep(0.1,nbehavior))
phi.true=phi
#look at these parameters
boxplot(theta)
apply(theta>0.95,2,mean)
par(mfrow=c(ceiling(nbehavior/2),2),mar=rep(1,4))
for (i in 1:nbehavior) plot(phi.true[[1]][i,],type='h',main=i)
for (i in 1:nbehavior) plot(phi.true[[2]][i,],type='h',main=i)
#create storage space
y.disagg.true=z.true=list()
for (i in 1:ndata.types){
z.true[[i]]=matrix(0,ntsegm,nbehavior)
y.disagg.true[[i]]=array(NA,dim=c(ntsegm,ncat.data[i],nbehavior))
}
#generate disaggregated data (already partitioned into different behaviors)
for (j in 1:ndata.types){
for (t in 1:ntsegm){
z=rmultinom(1,size=nobs.tsegm,prob=theta[t,]) #number of obs from each behavior
z.true[[j]][t,]=z
for (k in 1:nbehavior){
y.disagg.true[[j]][t,,k]=rmultinom(1,size=z[k],prob=phi[[j]][k,]) #number of obs in each categ from each behavior
}
}
}
#aggregate data
y=numeric()
for (j in 1:ndata.types){
aux=apply(y.disagg.true[[j]],1:2,sum) #sum across behaviors
nomes=paste0('y',j,'.',1:ncat.data[j])
colnames(aux)=nomes
y=cbind(y,aux)
}
plot(res$loglikel[100:ngibbs],type='l')
compare=function(true1,estim1){
rango=range(c(true1,estim1))
plot(true1,estim1,ylim=rango,xlim=rango)
lines(rango,rango,col='red')
}
theta.estim=matrix(res$theta[ngibbs,],nrow(dat),nmaxclust)
boxplot(theta.estim)
par(mfrow=c(1,1))
theta.estim=matrix(res$theta[ngibbs,],nrow(dat),nmaxclust)
boxplot(theta.estim)
nclust=5
z1.tmp=apply(res$z.agg[[1]],c(1,3),sum)[,1:nclust]
#find best order
ordem=numeric()
for (i in 1:ncol(z.true[[1]])){
tmp=rep(NA,ncol(z.true[[1]]))
for (j in 1:ncol(z1.tmp)){
tmp[j]=cor(cbind(z1.tmp[,j],z.true[[1]][,i]))[1,2]
}
ind=which(tmp==max(tmp))
ordem=c(ordem,ind)
}
par(mfrow=c(ceiling(ndata.types/2),2),mar=rep(1,4))
for (j in 1:ndata.types){
z1.tmp=apply(res$z.agg[[j]],c(1,3),sum)[,1:nclust]
compare(z.true[[j]],z1.tmp[,ordem])
}
compare(theta.true,theta.estim[,ordem])
par(mfrow=c(ceiling(ndata.types/2),2),mar=rep(1,4))
for (j in 1:ndata.types){
phi1.estim=matrix(res$phi[[j]][ngibbs,],nmaxclust,ncat.data[j])
compare(phi.true[[j]],phi1.estim[ordem,])
}
rm(list=ls(all=TRUE))
library('MCMCpack')
set.seed(3)
#basic settings
ntsegm=20*40 #overall number of time segments
#be careful with large nbehavior because it is easy to:
#- generate phi1 and phi2 in such a way that things are not clearly separable
#- generate theta in such a way that we don't have approx. pure time segments
nbehavior=3
ncat.data=c(6,10,2,8,5)
ndata.types=length(ncat.data)
nobs.tsegm=100 #number of observations per time segment
#get parameters
phi=list()
for (i in 1:ndata.types){
phi[[i]]=rdirichlet(nbehavior,alpha=rep(0.1,ncat.data[i]))
}
theta.true=theta=rdirichlet(ntsegm,alpha=rep(0.1,nbehavior))
phi.true=phi
#look at these parameters
boxplot(theta)
apply(theta>0.95,2,mean)
par(mfrow=c(ceiling(nbehavior/2),2),mar=rep(1,4))
for (i in 1:nbehavior) plot(phi.true[[1]][i,],type='h',main=i)
for (i in 1:nbehavior) plot(phi.true[[2]][i,],type='h',main=i)
#create storage space
y.disagg.true=z.true=list()
for (i in 1:ndata.types){
z.true[[i]]=matrix(0,ntsegm,nbehavior)
y.disagg.true[[i]]=array(NA,dim=c(ntsegm,ncat.data[i],nbehavior))
}
#generate disaggregated data (already partitioned into different behaviors)
for (j in 1:ndata.types){
for (t in 1:ntsegm){
z=rmultinom(1,size=nobs.tsegm,prob=theta[t,]) #number of obs from each behavior
z.true[[j]][t,]=z
for (k in 1:nbehavior){
y.disagg.true[[j]][t,,k]=rmultinom(1,size=z[k],prob=phi[[j]][k,]) #number of obs in each categ from each behavior
}
}
}
#aggregate data
y=numeric()
for (j in 1:ndata.types){
aux=apply(y.disagg.true[[j]],1:2,sum) #sum across behaviors
nomes=paste0('y',j,'.',1:ncat.data[j])
colnames(aux)=nomes
y=cbind(y,aux)
}
#export fake data
setwd('U:\\GIT_models\\git_LDA_behavior')
write.csv(y,'fake data.csv',row.names=F)
rm(list=ls(all=TRUE))
library('MCMCpack')
library('Rcpp')
set.seed(2)
setwd('U:\\GIT_models\\git_LDA_behavior')
source('LDA_behavior_function.R')
source('LDA_behavior_gibbs.R')
sourceCpp('aux1.cpp')
dat=read.csv('fake data.csv',as.is=T)
#prior
gamma1=0.1
alpha=0.1
#prepare for gibbs
ngibbs=1000
nburn=ngibbs/2
nmaxclust=10
ndata.types=5
res=LDA_behavior_gibbs(dat=dat,gamma1=gamma1,alpha=alpha,
ngibbs=ngibbs,nmaxclust=nmaxclust,
nburn=nburn,ndata.types=ndata.types)
rm(list=ls(all=TRUE))
library('MCMCpack')
library('Rcpp')
set.seed(2)
setwd('U:\\GIT_models\\git_LDA_behavior')
source('LDA_behavior_function.R')
source('LDA_behavior_gibbs.R')
sourceCpp('aux1.cpp')
dat=read.csv('fake data.csv',as.is=T)
gamma1=0.1
alpha=0.1
#prepare for gibbs
ngibbs=1000
nburn=ngibbs/2
nmaxclust=10
ndata.types=5
res=LDA_behavior_gibbs(dat=dat,gamma1=gamma1,alpha=alpha,
ngibbs=ngibbs,nmaxclust=nmaxclust,
nburn=nburn,ndata.types=ndata.types)
dat
head(dat)
rm(list=ls(all=TRUE))
library('MCMCpack')
library('Rcpp')
set.seed(2)
setwd('U:\\GIT_models\\git_LDA_behavior')
source('LDA_behavior_function.R')
source('LDA_behavior_gibbs.R')
sourceCpp('aux1.cpp')
dat=read.csv('fake data.csv',as.is=T)
#prior
gamma1=0.1
alpha=0.1
#prepare for gibbs
ngibbs=1000
nburn=ngibbs/2
nmaxclust=10
ndata.types=5
res=LDA_behavior_gibbs(dat=dat,gamma1=gamma1,alpha=alpha,
ngibbs=ngibbs,nmaxclust=nmaxclust,
nburn=nburn,ndata.types=ndata.types)
library('MCMCpack')
set.seed(3)
#basic settings
ntsegm=20*40 #overall number of time segments
#be careful with large nbehavior because it is easy to:
#- generate phi1 and phi2 in such a way that things are not clearly separable
#- generate theta in such a way that we don't have approx. pure time segments
nbehavior=3
ncat.data=c(6,10,2,8,5)
ndata.types=length(ncat.data)
nobs.tsegm=100 #number of observations per time segment
#get parameters
phi=list()
for (i in 1:ndata.types){
phi[[i]]=rdirichlet(nbehavior,alpha=rep(0.1,ncat.data[i]))
}
theta.true=theta=rdirichlet(ntsegm,alpha=rep(0.1,nbehavior))
phi.true=phi
#look at these parameters
boxplot(theta)
apply(theta>0.95,2,mean)
par(mfrow=c(ceiling(nbehavior/2),2),mar=rep(1,4))
for (i in 1:nbehavior) plot(phi.true[[1]][i,],type='h',main=i)
for (i in 1:nbehavior) plot(phi.true[[2]][i,],type='h',main=i)
#create storage space
y.disagg.true=z.true=list()
for (i in 1:ndata.types){
z.true[[i]]=matrix(0,ntsegm,nbehavior)
y.disagg.true[[i]]=array(NA,dim=c(ntsegm,ncat.data[i],nbehavior))
}
#generate disaggregated data (already partitioned into different behaviors)
for (j in 1:ndata.types){
for (t in 1:ntsegm){
z=rmultinom(1,size=nobs.tsegm,prob=theta[t,]) #number of obs from each behavior
z.true[[j]][t,]=z
for (k in 1:nbehavior){
y.disagg.true[[j]][t,,k]=rmultinom(1,size=z[k],prob=phi[[j]][k,]) #number of obs in each categ from each behavior
}
}
}
#aggregate data
y=numeric()
for (j in 1:ndata.types){
aux=apply(y.disagg.true[[j]],1:2,sum) #sum across behaviors
nomes=paste0('y',j,'.',1:ncat.data[j])
colnames(aux)=nomes
y=cbind(y,aux)
}
plot(res$loglikel[100:ngibbs],type='l')
compare=function(true1,estim1){
rango=range(c(true1,estim1))
plot(true1,estim1,ylim=rango,xlim=rango)
lines(rango,rango,col='red')
}
par(mfrow=c(1,1))
theta.estim=matrix(res$theta[ngibbs,],nrow(dat),nmaxclust)
boxplot(theta.estim)
nclust=3
z1.tmp=apply(res$z.agg[[1]],c(1,3),sum)[,1:nclust]
#find best order
ordem=numeric()
for (i in 1:ncol(z.true[[1]])){
tmp=rep(NA,ncol(z.true[[1]]))
for (j in 1:ncol(z1.tmp)){
tmp[j]=cor(cbind(z1.tmp[,j],z.true[[1]][,i]))[1,2]
}
ind=which(tmp==max(tmp))
ordem=c(ordem,ind)
}
#look at z's
par(mfrow=c(ceiling(ndata.types/2),2),mar=rep(1,4))
for (j in 1:ndata.types){
z1.tmp=apply(res$z.agg[[j]],c(1,3),sum)[,1:nclust]
compare(z.true[[j]],z1.tmp[,ordem])
}
#look at theta's
compare(theta.true,theta.estim[,ordem])
par(mfrow=c(ceiling(ndata.types/2),2),mar=rep(1,4))
for (j in 1:ndata.types){
phi1.estim=matrix(res$phi[[j]][ngibbs,],nmaxclust,ncat.data[j])
compare(phi.true[[j]],phi1.estim[ordem,])
}
rm(list=ls())
set.seed(21)
setwd('U:\\GIT_models\\resist')
n=50000
nparam=3
xmat=matrix(runif(n*nparam,min=-2,max=2),n,nparam)
nomes.cov=paste0('covs',1:nparam)
colnames(xmat)=nomes.cov
n=nrow(xmat)
ngroup=4
betas.true=betas=matrix(c( 2, 0 ,1,-2,
0, 2, 0,-1,
-1, 0, 0, 0,
0, 0, 2, 0),nparam+1,ngroup,byrow=T)
media=exp(cbind(1,xmat)%*%betas); range(round(media,3))
b.true=b=rep(1,ngroup)
bmat=matrix(b,n,ngroup,byrow=T)
a=bmat*media
ymat=matrix(rgamma(n*ngroup,a,b),n,ngroup);
fim=as.data.frame(xmat)
fim$z=NA
fim$ysoma=NA
fim$seg.id=NA
#aggregate these data
ind=floor(c(seq(from=1,to=n,by=n/5000),n+1)) #has to include 1 and n to use all observations
for (i in 2:length(ind)){
seq1=ind[i-1]:(ind[i]-1)
n=length(seq1)
fim$seg.id[seq1]=i-1
z=sample(1:ngroup,size=1)
fim$z[ind[i]-1]=z
ysoma=ymat[seq1,z]
fim$ysoma[ind[i]-1]=sum(ysoma)
}
max(fim$seg.id)
length(unique(fim$seg.id))
range(fim$ysoma,na.rm=T)
#get z.true
tmp=unique(fim[,c('z','seg.id')])
z.true=tmp[!is.na(tmp$z),'z']
table(z.true)
library('Rcpp')
set.seed(6)
setwd('U:\\GIT_models\\resist')
source('gibbs_resist.R')
source('gibbs_resist_func.R')
source('slice_b_gamma.R')
source('slice_betas.R')
sourceCpp('resist_aux.cpp')
dat=read.csv('fake data.csv',as.is=T)
ind=grep('cov',colnames(dat))
xmat=data.matrix(cbind(1,dat[,ind]))
seg.id=dat$seg.id
ngroup=4
#get y soma
tmp=unique(dat[,c('seg.id','ysoma')])
cond=!is.na(tmp$ysoma)
ysoma=tmp[cond,'ysoma']
ngibbs=1000
nburn=ngibbs/2
w=0.1
MaxIter=100
#priors
gamma1=0.1
var.betas=c(100,rep(10,ncol(xmat)-1))
n=nrow(xmat)
nparam=ncol(xmat)
nagg=length(ysoma)
#initial parameters
betas=matrix(0,nparam,ngroup)
betas[1,]=log(mean(ysoma))
b.gamma=rep(1,ngroup)
z=sample(1:ngroup,size=nagg,replace=T)
theta=rep(1/ngroup,ngroup)
#stuff for gibbs sampler
jump1=list(betas=matrix(0.1,nparam,ngroup),b.gamma=rep(0.1,ngroup))
accept1=list(betas=matrix(0,nparam,ngroup),b.gamma=rep(0,ngroup))
store.betas=matrix(NA,ngibbs,nparam*ngroup)
store.b=matrix(NA,ngibbs,ngroup)
store.theta=matrix(NA,ngibbs,ngroup)
store.llk=matrix(NA,ngibbs,1)
accept.output=50
for (i in 1:ngibbs){
print(i)
#sample betas
# betas=Sample_betas(ngroups=ngroup,nparam=nparam,xmat=xmat,z=z,
#                    ysoma=ysoma,betas=betas,b.gamma=b.gamma,var.betas=var.betas,
#                    w=w,MaxIter=MaxIter,seg.id=seg.id,nagg=nagg)
# tmp=sample.betas(betas=betas,xmat=xmat,ysoma=ysoma,jump=jump1$betas,
#                  b.gamma=b.gamma,nparam=nparam,var.betas=var.betas,
#                  seg.id=seg.id,ngroup=ngroup,nagg=nagg,z=z)
# betas=tmp$betas
# accept1$betas=accept1$betas+tmp$accept
betas=betas.true
#sample b.gamma
b.gamma=Sample_bgamma(ngroups=ngroup,nparam=nparam,xmat=xmat,
z=z,ysoma=ysoma,betas=betas,b.gamma=b.gamma,
w=w,MaxIter=MaxIter,seg.id=seg.id,nagg=nagg)
# tmp=sample.b.gamma(betas=betas,xmat=xmat,ysoma=ysoma,jump=jump1$b.gamma,
#                    b.gamma=b.gamma,seg.id=seg.id,ngroup=ngroup,nagg=nagg,z=z)
# b.gamma=tmp$b.gamma
# accept1$b.gamma=accept1$b.gamma+tmp$accept
# b.gamma=b.true
#sample z
# z=sample.z(betas=betas,xmat=xmat,ysoma=ysoma,b.gamma=b.gamma,
#            seg.id=seg.id,ngroup=ngroup,nagg=nagg,theta=theta)
z=z.true
#sample theta
theta=rep(1/ngroup,ngroup)
#get llk
p=get.llk(betas=betas,xmat=xmat,ysoma=ysoma,b.gamma=b.gamma,
seg.id=seg.id,ngroup=ngroup,nagg=nagg)
#sum the loglikel for the correct group
llk1=GetSomaLlkGroups(llk=p, z=z-1, ngroups=ngroup)
#adaptation MH algorithm
if (i<nburn & i%%accept.output==0){
k=print.adapt(accept1z=accept1,jump1z=jump1,accept.output=accept.output)
accept1=k$accept1
jump1=k$jump1
}
#store results
store.betas[i,]=betas
store.b[i,]=b.gamma
store.llk[i]=sum(llk1)
store.theta[i,]=theta
z.estim=z
}
par(mfrow=c(2,ceiling(ngroup/2)))
for (i in 1:ngroup) plot(store.b[,i],type='l')
for (i in 1:ngroup) {
plot(store.b[nburn:ngibbs,i],type='l')
abline(h=b.true[i],col='red')
}
